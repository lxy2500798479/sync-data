#!/usr/bin/env python3
"""
å°†çŸ¥è¯†åº“æ•°æ®ä¸Šä¼ åˆ° API æ¥å£
ä» PostgreSQL è¯»å–æ•°æ®ï¼Œè½¬æ¢ä¸ºæŒ‡å®šæ ¼å¼ï¼Œæ‰¹é‡ä¸Šä¼ 
"""

import os
import uuid
import json
import requests
from typing import List, Dict, Any
from datetime import datetime
from dotenv import load_dotenv
from tqdm import tqdm

# å¯¼å…¥ç°æœ‰çš„æ•°æ®åº“æ¨¡å—
from sync_data.database import PostgreSQLConnection

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# ============= é…ç½®åŒºåŸŸï¼ˆåœ¨è¿™é‡Œä¿®æ”¹ï¼‰ =============
COMPANY_ID = "01998d91-d276-76b3-a5dc-00a580cafd93"  # ğŸ“ å…¬å¸ID
DB_COLLECTION_NAME = "chat_shangtong_faq_v0"  # ğŸ“ é›†åˆåç§°
API_URL = "https://ai-toolkit.wyts.tech/v0/vector/document/save"
ACCESS_TOKEN = "sUwzcwDE7YgwYa8fvq6c"  # ğŸ“ è®¿é—®ä»¤ç‰Œ
VERSION = "1.0.0"  # ğŸ“ ç‰ˆæœ¬å·
BATCH_SIZE = 10  # âš ï¸ API é™åˆ¶ï¼šæ¯æ‰¹æœ€å¤š 10 æ¡
# ================================================


class APIUploader:
    """API ä¸Šä¼ å™¨"""
    
    def __init__(self, api_url: str = API_URL):
        self.api_url = api_url
        self.db = PostgreSQLConnection()  # ä»ç¯å¢ƒå˜é‡è‡ªåŠ¨è¯»å–é…ç½®
    
    def transform_to_api_format(self, intent: Dict[str, Any], question: str, 
                               answers: List[Dict[str, Any]]) -> Dict[str, Any]:
        """
        è½¬æ¢ä¸º API æ‰€éœ€çš„æ ¼å¼
        
        Args:
            intent: æ„å›¾æ•°æ®
            question: æ ‡å‡†é—®é¢˜
            answers: ç­”æ¡ˆåˆ—è¡¨
            
        Returns:
            API æ ¼å¼çš„æ–‡æ¡£
        """
        # ä½¿ç”¨ intent ID ä½œä¸ºæ–‡æ¡£ IDï¼ˆå›ºå®šï¼‰
        doc_id = intent['id']
        
        # æ„å»ºç²¾ç®€çš„ metadata
        metadata = {
            "companyId": intent['company_id'],
            "intentName": intent['name'],
            "version": VERSION,  # ç‰ˆæœ¬å·
            "level": "é€šç”¨",  # é»˜è®¤çº§åˆ«
            "sort": 'order',
            "answers": []
        }
        
        # å¤„ç†ç­”æ¡ˆï¼Œå°† content è½¬æ¢ä¸ºå­—ç¬¦ä¸²æ•°ç»„
        for ans in answers:
            if not ans.get('is_active'):
                continue
                
            content_data = ans.get('content', {})
            content_array = []
            
            # å¤„ç†ä¸åŒæ ¼å¼çš„ content
            if isinstance(content_data, dict):
                text = content_data.get('text', '')
                if isinstance(text, list):
                    # å¦‚æœæ˜¯åˆ—è¡¨ï¼Œç›´æ¥ä½¿ç”¨
                    content_array = [str(item) for item in text if item]
                elif isinstance(text, str) and text:
                    # å¦‚æœæ˜¯å­—ç¬¦ä¸²ï¼ŒåŒ…è£…æˆåˆ—è¡¨
                    content_array = [text]
            elif isinstance(content_data, str):
                # å¦‚æœ content æœ¬èº«å°±æ˜¯å­—ç¬¦ä¸²
                content_array = [content_data]
            
            # åªæ·»åŠ æœ‰å†…å®¹çš„ç­”æ¡ˆ
            if content_array:
                metadata['answers'].append({
                    "content": content_array
                })
        
        return {
            "id": doc_id,
            "content": question,
            "metadata": metadata
        }
    
    def fetch_company_data(self, company_id: str) -> List[Dict[str, Any]]:
        """
        è·å–å…¬å¸çš„æ‰€æœ‰çŸ¥è¯†åº“æ•°æ®
        
        Args:
            company_id: å…¬å¸ ID
            
        Returns:
            è½¬æ¢åçš„æ–‡æ¡£åˆ—è¡¨
        """
        print(f"\n{'='*60}")
        print(f"ğŸ“¦ æ­£åœ¨è·å–å…¬å¸æ•°æ®: {company_id}")
        print(f"{'='*60}\n")
        
        # è·å–æ‰€æœ‰æ´»è·ƒæ„å›¾
        intents = self.db.get_company_intents(company_id)
        print(f"âœ… æ‰¾åˆ° {len(intents)} ä¸ªæ„å›¾")
        
        # ğŸš€ æ€§èƒ½ä¼˜åŒ–ï¼šæ‰¹é‡è·å–æ‰€æœ‰ç­”æ¡ˆï¼ˆé¿å… N+1 æŸ¥è¯¢ï¼‰
        intent_ids = [intent['id'] for intent in intents]
        print(f"ğŸ” æ‰¹é‡æŸ¥è¯¢æ‰€æœ‰ç­”æ¡ˆ...")
        answers_map = self.db.get_answers_by_intent_ids(intent_ids)
        print(f"âœ… æŸ¥è¯¢å®Œæˆ")
        
        documents = []
        
        # å¤„ç†æ¯ä¸ªæ„å›¾
        for intent in tqdm(intents, desc="å¤„ç†æ„å›¾"):
            intent_id = intent['id']
            keywords = intent.get('keywords', [])
            
            if not keywords:
                continue
            
            # ä»å†…å­˜ä¸­è·å–ç­”æ¡ˆï¼ˆä¸å†æŸ¥è¯¢æ•°æ®åº“ï¼‰
            answers = answers_map.get(intent_id, [])
            
            # ä¸ºæ¯ä¸ªæ ‡å‡†é—®é¢˜ç”Ÿæˆä¸€ä¸ªæ–‡æ¡£
            for question in keywords:
                doc = self.transform_to_api_format(intent, question, answers)
                documents.append(doc)
        
        print(f"\nâœ… å…±ç”Ÿæˆ {len(documents)} ä¸ªæ–‡æ¡£")
        return documents
    
    def upload_batch(self, db_collection_name: str, documents: List[Dict[str, Any]]) -> Dict[str, Any]:
        """
        ä¸Šä¼ ä¸€æ‰¹æ–‡æ¡£åˆ° API
        
        Args:
            db_collection_name: é›†åˆåç§°
            documents: æ–‡æ¡£åˆ—è¡¨ï¼ˆæœ€å¤š 500 ä¸ªï¼‰
            
        Returns:
            API å“åº”
        """
        payload = {
            "dbCollectionName": db_collection_name,
            "dimensions": 768,
            "documents": documents
        }
        
        try:
            response = requests.post(
                self.api_url,
                json=payload,
                headers={
                    "Content-Type": "application/json",
                    "Access-Token": ACCESS_TOKEN
                },
                timeout=60
            )
            
            response.raise_for_status()
            return response.json()
            
        except requests.exceptions.RequestException as e:
            print(f"âŒ ä¸Šä¼ å¤±è´¥: {e}")
            if hasattr(e, 'response') and e.response is not None:
                print(f"   å“åº”å†…å®¹: {e.response.text}")
            raise
    
    def upload_company_data(self, company_id: str):
        """
        ä¸Šä¼ å…¬å¸çš„æ‰€æœ‰æ•°æ®
        
        Args:
            company_id: å…¬å¸ ID
        """
        # è·å–æ‰€æœ‰æ–‡æ¡£
        documents = self.fetch_company_data(company_id)
        
        if not documents:
            print("âš ï¸ æ²¡æœ‰æ•°æ®éœ€è¦ä¸Šä¼ ")
            return
        
        # åˆ†æ‰¹ä¸Šä¼ 
        total_batches = (len(documents) + BATCH_SIZE - 1) // BATCH_SIZE
        print(f"\n{'='*60}")
        print(f"ğŸ“¤ å¼€å§‹ä¸Šä¼ æ•°æ®")
        print(f"   APIåœ°å€: {self.api_url}")
        print(f"   é›†åˆåç§°: {DB_COLLECTION_NAME}")
        print(f"   æ€»æ–‡æ¡£æ•°: {len(documents)}")
        print(f"   æ‰¹æ¬¡æ•°: {total_batches}")
        print(f"   æ¯æ‰¹å¤§å°: {BATCH_SIZE}")
        print(f"{'='*60}\n")
        
        success_count = 0
        
        for i in range(0, len(documents), BATCH_SIZE):
            batch = documents[i:i + BATCH_SIZE]
            batch_num = (i // BATCH_SIZE) + 1
            
            print(f"ğŸ“¤ ä¸Šä¼ æ‰¹æ¬¡ {batch_num}/{total_batches} ({len(batch)} ä¸ªæ–‡æ¡£)...")
            
            try:
                result = self.upload_batch(DB_COLLECTION_NAME, batch)
                print(f"âœ… æ‰¹æ¬¡ {batch_num} ä¸Šä¼ æˆåŠŸ")
                print(f"   å“åº”: {json.dumps(result, ensure_ascii=False)}")
                success_count += len(batch)
                
            except Exception as e:
                print(f"âŒ æ‰¹æ¬¡ {batch_num} ä¸Šä¼ å¤±è´¥: {e}")
                # å¯ä»¥é€‰æ‹©ç»§ç»­æˆ–åœæ­¢
                choice = input("æ˜¯å¦ç»§ç»­ä¸‹ä¸€æ‰¹ï¼Ÿ(y/n): ")
                if choice.lower() != 'y':
                    break
        
        print(f"\n{'='*60}")
        print(f"âœ… ä¸Šä¼ å®Œæˆï¼")
        print(f"   æˆåŠŸ: {success_count}/{len(documents)}")
        print(f"{'='*60}")
    
    def close(self):
        """å…³é—­æ•°æ®åº“è¿æ¥ï¼ˆPostgreSQLConnection è‡ªåŠ¨ç®¡ç†è¿æ¥ï¼‰"""
        pass  # ä¸éœ€è¦æ‰‹åŠ¨å…³é—­


def show_menu():
    """æ˜¾ç¤ºäº¤äº’å¼èœå•"""
    print("\n" + "="*60)
    print("ğŸš€ çŸ¥è¯†åº“æ•°æ®ä¸Šä¼ å·¥å…·")
    print("="*60)
    print("è¯·é€‰æ‹©æ“ä½œï¼š")
    print("  1. ğŸ“„ æŸ¥çœ‹é¢„è§ˆæ•°æ®ï¼ˆä¸ä¸Šä¼ ï¼‰")
    print("  2. ğŸ“¤ ä¸Šä¼ æ•°æ®åˆ° API")
    print("  3. âŒ é€€å‡º")
    print("="*60)
    
    while True:
        choice = input("è¯·è¾“å…¥é€‰é¡¹ (1/2/3): ").strip()
        if choice in ['1', '2', '3']:
            return choice
        print("âŒ æ— æ•ˆé€‰é¡¹ï¼Œè¯·è¾“å…¥ 1ã€2 æˆ– 3")


def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description='ä¸Šä¼ çŸ¥è¯†åº“æ•°æ®åˆ° API')
    parser.add_argument('--preview', action='store_true', help='é¢„è§ˆæ•°æ®æ ¼å¼ï¼Œä¸å®é™…ä¸Šä¼ ')
    parser.add_argument('--upload', action='store_true', help='ç›´æ¥ä¸Šä¼ æ•°æ®ï¼Œä¸æ˜¾ç¤ºèœå•')
    
    args = parser.parse_args()
    
    # ä½¿ç”¨é…ç½®ä¸­çš„å…¬å¸ID
    company_id = COMPANY_ID
    
    print(f"\nğŸ“¦ é…ç½®ä¿¡æ¯:")
    print(f"   å…¬å¸ID: {company_id}")
    print(f"   é›†åˆåç§°: {DB_COLLECTION_NAME}")
    print(f"   APIåœ°å€: {API_URL}")
    print(f"   Access-Token: {ACCESS_TOKEN[:10]}...{ACCESS_TOKEN[-4:]}\n")
    
    uploader = APIUploader()
    
    try:
        # ç¡®å®šæ“ä½œæ¨¡å¼
        if args.preview:
            # å‘½ä»¤è¡Œå‚æ•°ï¼šé¢„è§ˆæ¨¡å¼
            mode = '1'
        elif args.upload:
            # å‘½ä»¤è¡Œå‚æ•°ï¼šä¸Šä¼ æ¨¡å¼
            mode = '2'
        else:
            # äº¤äº’å¼èœå•
            mode = show_menu()
        
        if mode == '1':
            # é¢„è§ˆæ¨¡å¼ï¼šåªè·å–æ•°æ®ï¼Œä¸ä¸Šä¼ 
            print("\nğŸ” é¢„è§ˆæ¨¡å¼ï¼šè·å–æ•°æ®æ ¼å¼...\n")
            documents = uploader.fetch_company_data(company_id)
            
            if documents:
                print("\n" + "="*60)
                print("ğŸ“„ ç¤ºä¾‹æ–‡æ¡£ï¼ˆå‰ 3 ä¸ªï¼‰:")
                print("="*60)
                for i, doc in enumerate(documents[:3], 1):
                    print(f"\næ–‡æ¡£ {i}:")
                    print(json.dumps(doc, ensure_ascii=False, indent=2))
                
                print("\n" + "="*60)
                print(f"ğŸ“¦ é›†åˆåç§°: {DB_COLLECTION_NAME}")
                print(f"âœ… å…± {len(documents)} ä¸ªæ–‡æ¡£")
                print(f"ğŸ’¾ é¢„è®¡è¯·æ±‚æ¬¡æ•°: {(len(documents) + BATCH_SIZE - 1) // BATCH_SIZE}")
                print("="*60)
                
                # è¯¢é—®æ˜¯å¦å¯¼å‡ºJSONæ–‡ä»¶
                print("\nğŸ’¾ æ˜¯å¦å¯¼å‡ºä¸ºJSONæ–‡ä»¶ï¼Ÿ")
                export_choice = input("è¯·è¾“å…¥ (y/n): ").strip().lower()
                if export_choice == 'y':
                    # ç”Ÿæˆæ–‡ä»¶åï¼ˆå¸¦æ—¶é—´æˆ³ï¼‰
                    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                    filename = f"preview_data_{timestamp}.json"
                    
                    # æ„å»ºå®Œæ•´çš„å¯¼å‡ºæ•°æ®ç»“æ„
                    export_data = {
                        "exportTime": datetime.now().isoformat(),
                        "companyId": company_id,
                        "dbCollectionName": DB_COLLECTION_NAME,
                        "totalDocuments": len(documents),
                        "version": VERSION,
                        "documents": documents
                    }
                    
                    # å†™å…¥æ–‡ä»¶
                    with open(filename, 'w', encoding='utf-8') as f:
                        json.dump(export_data, f, ensure_ascii=False, indent=2)
                    
                    print(f"\nâœ… æ•°æ®å·²å¯¼å‡ºåˆ°: {filename}")
                    print(f"ğŸ“Š æ–‡ä»¶å¤§å°: {os.path.getsize(filename) / 1024:.2f} KB")
                else:
                    print("âŒ å·²å–æ¶ˆå¯¼å‡º")
            else:
                print("âš ï¸ æ²¡æœ‰æ‰¾åˆ°æ•°æ®")
        
        elif mode == '2':
            # æ­£å¼ä¸Šä¼ 
            print("\nâš ï¸  å³å°†ä¸Šä¼ æ•°æ®åˆ° APIï¼Œæ˜¯å¦ç»§ç»­ï¼Ÿ")
            confirm = input("è¯·è¾“å…¥ yes ç¡®è®¤: ").strip().lower()
            if confirm == 'yes':
                uploader.upload_company_data(company_id)
            else:
                print("âŒ å·²å–æ¶ˆä¸Šä¼ ")
        
        elif mode == '3':
            # é€€å‡º
            print("ğŸ‘‹ å†è§ï¼")
            return
    
    finally:
        uploader.close()


if __name__ == "__main__":
    main()

